{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets train our first neural network!\n",
    "To train a neural network we need two things.\n",
    "\n",
    "1.A dataset with a classifier to train on\n",
    "2.A mathematical neural network\n",
    "\n",
    "## Task default dataset from my brain\n",
    "![alt text](brainsensor.jpg)\n",
    "\n",
    "To make it fun, lets use a dataset that takes input from brain data  measured with laser sensors to try to determine what brain region is active, the default mode network or the task positive network.\n",
    "\n",
    "The goal is to try to detect activation in the default mode network or task positive networks on the brain with the help of FNIRS data.\n",
    "\n",
    "## Introduction to the dataset\n",
    "![alt text](dmn2.jpg)\n",
    "When you are working with data you need domain knowledge in order to understand it. This dataset is related to neuroscience but the same is true no matter what data you are working with.\n",
    "\n",
    "## The default mode network\n",
    "![alt text](dmn.jpeg)\n",
    "The default mode network is a brain area that is active during rest.\n",
    "\n",
    "It is the neurological basis for the self\n",
    "\n",
    "Autobiographical information: Memories of collection of events and facts about one's self Self-reference: Referring to traits and descriptions of one's self Emotion of one's self: Reflecting about one's own emotional state Thinking about others:\n",
    "\n",
    "Theory of Mind: Thinking about the thoughts of others and what they might or might not know Emotions of other: Understanding the emotions of other people and empathizing with their feelings Moral reasoning: Determining just and unjust result of an action Social evaluations: Good-bad attitude judgments about social concepts Social categories: Reflecting on important social characteristics and status of a group Remembering the past and thinking about the future:\n",
    "\n",
    "Remembering the past: Recalling events that happened in the past Imagining the future: Envisioning events that might happen in the future Episodic memory: Detailed memory related to specific events in time Story comprehension: Understanding and remembering a narrative The default mode network is active during passive rest and mind-wandering. Mind-wandering usually involves thinking about others, thinking about one's self, remembering the past, and envisioning the future. Electrocorticography studies (which involve placing electrodes on the surface of epileptic patient's brains) have shown the default mode network becomes activated within an order of a fraction of a second after participants finish a task.\n",
    "\n",
    "## The task positive network\n",
    "![alt text](tpn.png)\n",
    "The task positive network is active when you are doing a task and focusing your attention. The task-positive network (TPN) is a network of areas in the human brain that typically responds with activation increases to attention-demanding tasks in functional imaging studies. The task-positive network encompasses regions of the dorsal attention system, but in addition includes dorsolateral and ventrolateral prefrontal regions, the insular cortex, and the SMA/pre-SMA. Notably, the nodes of this network are also correlated during rest (i.e., in the absence of any task). The task-positive network is anti-correlated with the default mode network.\n",
    "\n",
    "During rest the TPN has been claimed to subserve intermittent \"external awareness\", defined as the conscious perception through different sensory modalities of one's surrounding environment[further explanation needed]. alt text\n",
    "\n",
    "Anticorrelations\n",
    "The task positive network and the default mode network are anti-correlated brain regions and you spend your time in either brain region.\n",
    "\n",
    "Classifying brain region activation\n",
    "The goal of this assignment is to see if we can make a classifier that can understand what brain region is active.\n",
    "\n",
    "Feedforward neural network\n",
    "\n",
    "\n",
    "Calculated on an individual users file\n",
    "Changing the value in pd.read_csv changes the user that the model trains on\n",
    "This model uses a feedforward neural network on the data from the user\n",
    "The data is randomized and 50% of the dataset is user for training and 50% for testing\n",
    "X = input from the 52 broadmann areas at each timestep\n",
    "Y = REST or ADDITION from the Mark column of the dataset\n",
    "The model tries learns and tries to predict if each timeserie of data from the 52 broadmann areas is REST (Default mode network) or Addition (Task positive network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-32e2752eac57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CH1</th>\n",
       "      <th>CH2</th>\n",
       "      <th>CH3</th>\n",
       "      <th>CH4</th>\n",
       "      <th>CH5</th>\n",
       "      <th>CH6</th>\n",
       "      <th>CH7</th>\n",
       "      <th>CH8</th>\n",
       "      <th>CH9</th>\n",
       "      <th>CH10</th>\n",
       "      <th>...</th>\n",
       "      <th>CH46</th>\n",
       "      <th>CH47</th>\n",
       "      <th>CH48</th>\n",
       "      <th>CH49</th>\n",
       "      <th>CH50</th>\n",
       "      <th>CH51</th>\n",
       "      <th>CH52</th>\n",
       "      <th>FILENUM</th>\n",
       "      <th>IDNUM</th>\n",
       "      <th>YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.000000</td>\n",
       "      <td>1312.00000</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>1312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.095577</td>\n",
       "      <td>-0.089498</td>\n",
       "      <td>-0.101605</td>\n",
       "      <td>-0.146645</td>\n",
       "      <td>-0.144295</td>\n",
       "      <td>-0.140821</td>\n",
       "      <td>-0.289462</td>\n",
       "      <td>-0.159554</td>\n",
       "      <td>-0.058879</td>\n",
       "      <td>-0.091385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072193</td>\n",
       "      <td>-0.094931</td>\n",
       "      <td>-0.042203</td>\n",
       "      <td>-0.114156</td>\n",
       "      <td>-0.183224</td>\n",
       "      <td>-0.164694</td>\n",
       "      <td>-0.167940</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.396378</td>\n",
       "      <td>0.414639</td>\n",
       "      <td>0.434003</td>\n",
       "      <td>0.391896</td>\n",
       "      <td>0.371542</td>\n",
       "      <td>0.366168</td>\n",
       "      <td>0.415347</td>\n",
       "      <td>0.345969</td>\n",
       "      <td>0.110464</td>\n",
       "      <td>0.137309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343391</td>\n",
       "      <td>0.333648</td>\n",
       "      <td>0.331658</td>\n",
       "      <td>0.367759</td>\n",
       "      <td>0.365952</td>\n",
       "      <td>0.382460</td>\n",
       "      <td>0.293988</td>\n",
       "      <td>1.11846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.000515</td>\n",
       "      <td>-3.254711</td>\n",
       "      <td>-2.941266</td>\n",
       "      <td>-3.064770</td>\n",
       "      <td>-2.924323</td>\n",
       "      <td>-2.650335</td>\n",
       "      <td>-2.943172</td>\n",
       "      <td>-2.901140</td>\n",
       "      <td>-0.518711</td>\n",
       "      <td>-0.830974</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.488395</td>\n",
       "      <td>-2.480846</td>\n",
       "      <td>-2.330671</td>\n",
       "      <td>-2.634179</td>\n",
       "      <td>-2.497969</td>\n",
       "      <td>-2.844047</td>\n",
       "      <td>-2.632690</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.082048</td>\n",
       "      <td>-0.054599</td>\n",
       "      <td>-0.163848</td>\n",
       "      <td>-0.239178</td>\n",
       "      <td>-0.148317</td>\n",
       "      <td>-0.211297</td>\n",
       "      <td>-0.493398</td>\n",
       "      <td>-0.179088</td>\n",
       "      <td>-0.115749</td>\n",
       "      <td>-0.130255</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083285</td>\n",
       "      <td>-0.100979</td>\n",
       "      <td>-0.086187</td>\n",
       "      <td>-0.205575</td>\n",
       "      <td>-0.373848</td>\n",
       "      <td>-0.359300</td>\n",
       "      <td>-0.260987</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.032667</td>\n",
       "      <td>-0.009073</td>\n",
       "      <td>-0.041451</td>\n",
       "      <td>-0.037456</td>\n",
       "      <td>-0.070789</td>\n",
       "      <td>-0.076098</td>\n",
       "      <td>-0.141227</td>\n",
       "      <td>-0.089140</td>\n",
       "      <td>-0.061119</td>\n",
       "      <td>-0.067563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018623</td>\n",
       "      <td>-0.033346</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>-0.017384</td>\n",
       "      <td>-0.090455</td>\n",
       "      <td>-0.047510</td>\n",
       "      <td>-0.141541</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001181</td>\n",
       "      <td>0.025874</td>\n",
       "      <td>0.098225</td>\n",
       "      <td>0.046711</td>\n",
       "      <td>-0.020461</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>-0.086423</td>\n",
       "      <td>-0.028107</td>\n",
       "      <td>-0.009696</td>\n",
       "      <td>-0.012617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050821</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.109740</td>\n",
       "      <td>0.069420</td>\n",
       "      <td>0.050345</td>\n",
       "      <td>0.063153</td>\n",
       "      <td>-0.062023</td>\n",
       "      <td>2.25000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.267535</td>\n",
       "      <td>0.114364</td>\n",
       "      <td>0.288223</td>\n",
       "      <td>0.222436</td>\n",
       "      <td>0.117891</td>\n",
       "      <td>0.231293</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>0.150766</td>\n",
       "      <td>0.850856</td>\n",
       "      <td>0.519929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237260</td>\n",
       "      <td>0.214923</td>\n",
       "      <td>0.262689</td>\n",
       "      <td>0.190082</td>\n",
       "      <td>0.403533</td>\n",
       "      <td>0.341049</td>\n",
       "      <td>0.516628</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CH1          CH2          CH3          CH4          CH5  \\\n",
       "count  1312.000000  1312.000000  1312.000000  1312.000000  1312.000000   \n",
       "mean     -0.095577    -0.089498    -0.101605    -0.146645    -0.144295   \n",
       "std       0.396378     0.414639     0.434003     0.391896     0.371542   \n",
       "min      -3.000515    -3.254711    -2.941266    -3.064770    -2.924323   \n",
       "25%      -0.082048    -0.054599    -0.163848    -0.239178    -0.148317   \n",
       "50%      -0.032667    -0.009073    -0.041451    -0.037456    -0.070789   \n",
       "75%       0.001181     0.025874     0.098225     0.046711    -0.020461   \n",
       "max       0.267535     0.114364     0.288223     0.222436     0.117891   \n",
       "\n",
       "               CH6          CH7          CH8          CH9         CH10  \\\n",
       "count  1312.000000  1312.000000  1312.000000  1312.000000  1312.000000   \n",
       "mean     -0.140821    -0.289462    -0.159554    -0.058879    -0.091385   \n",
       "std       0.366168     0.415347     0.345969     0.110464     0.137309   \n",
       "min      -2.650335    -2.943172    -2.901140    -0.518711    -0.830974   \n",
       "25%      -0.211297    -0.493398    -0.179088    -0.115749    -0.130255   \n",
       "50%      -0.076098    -0.141227    -0.089140    -0.061119    -0.067563   \n",
       "75%       0.040976    -0.086423    -0.028107    -0.009696    -0.012617   \n",
       "max       0.231293     0.013531     0.150766     0.850856     0.519929   \n",
       "\n",
       "        ...           CH46         CH47         CH48         CH49  \\\n",
       "count   ...    1312.000000  1312.000000  1312.000000  1312.000000   \n",
       "mean    ...      -0.072193    -0.094931    -0.042203    -0.114156   \n",
       "std     ...       0.343391     0.333648     0.331658     0.367759   \n",
       "min     ...      -2.488395    -2.480846    -2.330671    -2.634179   \n",
       "25%     ...      -0.083285    -0.100979    -0.086187    -0.205575   \n",
       "50%     ...      -0.018623    -0.033346     0.008865    -0.017384   \n",
       "75%     ...       0.050821     0.013901     0.109740     0.069420   \n",
       "max     ...       0.237260     0.214923     0.262689     0.190082   \n",
       "\n",
       "              CH50         CH51         CH52     FILENUM   IDNUM    YEAR  \n",
       "count  1312.000000  1312.000000  1312.000000  1312.00000  1312.0  1312.0  \n",
       "mean     -0.183224    -0.164694    -0.167940     1.50000    20.0  2015.0  \n",
       "std       0.365952     0.382460     0.293988     1.11846     0.0     0.0  \n",
       "min      -2.497969    -2.844047    -2.632690     0.00000    20.0  2015.0  \n",
       "25%      -0.373848    -0.359300    -0.260987     0.75000    20.0  2015.0  \n",
       "50%      -0.090455    -0.047510    -0.141541     1.50000    20.0  2015.0  \n",
       "75%       0.050345     0.063153    -0.062023     2.25000    20.0  2015.0  \n",
       "max       0.403533     0.341049     0.516628     3.00000    20.0  2015.0  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-908b4f212169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# makes the values between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m52\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"normal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    101\u001b[0m                                          \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_initializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                                          \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                                          constraint=self.gamma_constraint)\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    397\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# TODO: move to `tf.get_variable` when supported in public release.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import keras\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "dataset = pd.read_csv(\"data/ID-OXY-20.csv\")\n",
    "# split into input (X) and output 󰀀 variables\n",
    "\n",
    "# Remove missing values\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# make a label dataset\n",
    "dataset[\"Label\"] = dataset[\"Mark\"]\n",
    "\n",
    "# change rest values to \n",
    "# default mode\n",
    "dataset[\"Mark\"][dataset[\"Mark\"] == \"REST\"] = 0\n",
    "# task positive network\n",
    "dataset[\"Mark\"][dataset[\"Mark\"] == \"ADDITION\"] = 1\n",
    "dataset[\"Mark\"][dataset[\"Mark\"] == \"PASSTHOUGHT\"] = 2\n",
    "dataset[\"Mark\"][dataset[\"Mark\"] == \"JUNK\"] = 3\n",
    "\n",
    "# remove the JUNK data\n",
    "dataset = dataset[dataset.Mark != 2]\n",
    "dataset = dataset[dataset.Mark != 3]\n",
    "\n",
    "# shuffle the data\n",
    "dataset = dataset.sample(frac=1)\n",
    "\n",
    "# 52 broadmann areas data\n",
    "X = np.array(dataset.ix[:, :'CH52'])\n",
    "# default mode network or task positive network\n",
    "Y = np.array([[1,0] if i == 0 else [0,1] for i in dataset.Mark])\n",
    "\n",
    "# Dropout - the number of neurons removed at each layers, who are readded when testing\n",
    "# Batch size - the number of data points added at each time, affects training time\n",
    "# Epochs - the number of training/test sessions\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# makes the values between 0 and 1\n",
    "#model.add(BatchNormalization(input_shape=(52,)))\n",
    "#model.add(Dropout(0.3))\n",
    "model.add(Dense(100, init=\"normal\", activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, init=\"normal\", activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(100, init=\"normal\", activation='relu'))\n",
    "\n",
    "model.add(Dense(2, init=\"normal\", activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.5, nb_epoch=50, batch_size=50, verbose=1)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Here is how you can save a trained model.\n",
    "\n",
    "# Save a trained model\n",
    "\n",
    "# save the trained model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"taskdefault.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"taskdefault.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-86e14ba6ffd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'save_img'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-06b29a23c178>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m model.add(Conv2D(32, kernel_size=(3, 3),\n\u001b[1;32m     48\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                  input_shape=input_shape))\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    132\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kernel'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             self.bias = self.add_weight(shape=(self.filters,),\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[1;32m    397\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                             constraint=constraint)\n\u001b[0m\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(value, dtype, name, constraint)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_learning_phase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# TODO: move to `tf.get_variable` when supported in public release.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
